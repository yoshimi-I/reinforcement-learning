{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 強化学習で実装したいもの\n",
    "- 方策\n",
    "    - π(a = a1|s1) = 0.3\n",
    "        - 状態s1の時にa1を行う確率は0.3\n",
    "        - 最終的にはこの方策が1つに決まる。(つまり100％これと言えるものを得る)\n",
    "                - それがゴール\n",
    "- 状態遷移確率\n",
    "    - p(s = s2|s1,a = a1) = 0.6\n",
    "        - 主にs = s1の時に方策の確率に従いa1の行動を実行した時にs2に映る確率を意味する。\n",
    "- 報酬\n",
    "    - r(s1,a,s1)\n",
    "        - 主にs1からaの行動を行い,s2に移動した時に発生する報酬\n",
    "- これらを用いて導き出せる漸化式がベルマン方程式\n",
    "    - つまりベルマン方程式を解けば、方策が1つにきまり、最適な解が見つかる。(決定論的な方策\n",
    "## 最終的に\n",
    "- 方策が1意に決まり、それに基づき状態価値関数も1位に決まる。\n",
    "- 今回は状態遷移確率は1とする(つまり行動が決まれば必ずその行動通りに動く)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "# 環境の実装\n",
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "\n",
    "        #行動は4種類(それぞれを数字に置き換える)\n",
    "        self.action_list = [0,1,2,3]\n",
    "        # 辞書型で行動を紐づける\n",
    "        self.action_meaning = {\n",
    "            0: \"UP\",\n",
    "            1: \"DOWN\",\n",
    "            2: \"LEFT\",\n",
    "            3: \"RIGHT\"\n",
    "        }\n",
    "        # 以下にマップを作成する\n",
    "        # それぞれの値はその場所の報酬を指す\n",
    "        self.reward_map = np.array(\n",
    "            [[0,0,0,1],\n",
    "            [0,None,0,-1],\n",
    "            [0,0,0,0],\n",
    "            [-1,0,-1,-1],\n",
    "            [0,0,0,0]]\n",
    "        )\n",
    "        #以下に障害物を記載し、その座標を保持\n",
    "        self.goal = (0,3)\n",
    "        self.start = (4,0)\n",
    "        self.wall = (1,1)\n",
    "        #エージェントの場所の配列を保持(スタート値で初期化)\n",
    "        self.agent_state = self.start\n",
    "\n",
    "    # 以下にメソッドを実装\n",
    "    # マップの情報を取得(主に再代入不可能のgetterの役割)\n",
    "    # 高さを返却\n",
    "    @property\n",
    "    def height(self):\n",
    "        return len(self.reward_map)\n",
    "    # 横幅を返却\n",
    "    @property\n",
    "    def width(self):\n",
    "        return len(self.reward_map[0])\n",
    "\n",
    "    #行動の種類を返却\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return self.action_list\n",
    "\n",
    "    def states(self):\n",
    "        for h in range(self.height):\n",
    "            for w in range(self.width):\n",
    "                yield (h,w)\n",
    "\n",
    "\n",
    "    # 以下にエージェントを動かすための関数と報酬関数を実装する。\n",
    "    def next_step(self,state,action):\n",
    "        # 上下左右の行動をそれぞれ座標に足し合わせることで実装\n",
    "        action_list = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "        # 0~3までの数字を配列に入れることで行動となる数値を取得\n",
    "        move = action_list[action]\n",
    "        # エージェントを移動させる(moveを現在の状態の座標に足し合わせる)\n",
    "        # next_state = (y座標,x座標)となる\n",
    "        next_state = (state[0] + move[0],state[1] + move[1])\n",
    "        new_y,new_x = next_state\n",
    "\n",
    "        # 移動したのちそれがマップから外れてるかどうかの確認処理(外れていたら更新を中断)\n",
    "        if new_x < 0 or new_x >= self.width or new_y < 0 or new_y >= self.height or next_state == self.wall:\n",
    "            next_state = state\n",
    "        return next_state #(2,3)みたいに次の座標\n",
    "    # 報酬関数\n",
    "    def reward(self,state,action,next_state):\n",
    "        return self.reward_map[next_state] # 1みたいに移動先での報酬を受け取る"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "(0, 0)\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(1, 0)\n",
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(2, 2)\n",
      "(2, 3)\n",
      "(3, 0)\n",
      "(3, 1)\n",
      "(3, 2)\n",
      "(3, 3)\n",
      "(4, 0)\n",
      "(4, 1)\n",
      "(4, 2)\n",
      "(4, 3)\n",
      "{(0, 0): 0, (0, 1): 0, (0, 2): 0, (0, 3): 0, (1, 0): 0, (1, 1): 0, (1, 2): 0, (1, 3): 0, (2, 0): 0, (2, 1): 0, (2, 2): 0, (2, 3): 0, (3, 0): 0, (3, 1): 0, (3, 2): 0, (3, 3): 0, (4, 0): 0, (4, 1): 0, (4, 2): 0, (4, 3): 0}\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld()\n",
    "print(env.actions)\n",
    "V = {}\n",
    "for state in env.states():\n",
    "    V[state] = 0\n",
    "    print(state)\n",
    "print(V)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 動的計画法の実装\n",
    "## 必要なこと\n",
    "1. まずは状態価値関数を出力しなくてはいけない\n",
    "2. それが決まることで状態行動価値関数を次に実装することができる\n",
    "    - その状態行動価値関数を実装するために必要なのが反復方策評価\n",
    "\n",
    "## 以下に動的計画法を行い状態価値関数を導きだす\n",
    "- 方策はどのマスも一定で上下左右に1/4の確率で移動するため、これを辞書型配列で保持し、確率と行動の番号を紐づける\n",
    "-  動的計画法を用いて更新を続けていく\n",
    "- そのためには辞書型配列をまずは初期化する\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (0, 1): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (0, 2): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (0, 3): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (1, 0): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (1, 1): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (1, 2): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (1, 3): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (2, 0): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (2, 1): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (2, 2): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (2, 3): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (3, 0): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (3, 1): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (3, 2): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (3, 3): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (4, 0): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (4, 1): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (4, 2): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, (4, 3): {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}}\n",
      "[(0, 0), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(0, 1), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(0, 2), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(0, 3), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(1, 0), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(1, 1), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(1, 2), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(1, 3), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(2, 0), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(2, 1), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(2, 2), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(2, 3), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(3, 0), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(3, 1), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(3, 2), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(3, 3), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(4, 0), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(4, 1), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(4, 2), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n",
      "[(4, 3), {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}]\n"
     ]
    }
   ],
   "source": [
    "env2 = GridWorld()\n",
    "V = {}\n",
    "for state in env2.states():#(0,0),(0,1)...\n",
    "    V[state] = {0:0.25,1:0.25,2:0.25,3:0.25}\n",
    "print(V)\n",
    "for i,j in V.items():\n",
    "    print([i,j])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "# 以下に動的計画法の実装関数を書く\n",
    "def eval_step(pi,V,env,gamma=0.9):\n",
    "    # stateで全ての座標にアクセスして価値関数を更新していく(最後までエピソードが終わった時の報酬がその場所の価値関数になる)\n",
    "    for state in env.states():#(0,0),(0,1)...\n",
    "        # アクセスした座標がゴールだった場合は価値関数は0なので0にする\n",
    "        if state == env.goal:\n",
    "            V[state] = 0\n",
    "            continue\n",
    "        action_probs = pi[state] #{0:0.25,1:0.25,2:0.25,3:0.25}\n",
    "        new_V = 0\n",
    "\n",
    "        # 各座標と方策を取得\n",
    "        for action,action_prob in action_probs.items():# action=0 action_prob=0.25\n",
    "            next_state = env.next_step(state,action)\n",
    "            r = env.reward(state,action,next_state)\n",
    "            # 価値関数を更新していく(動的計画法)\n",
    "            new_V += action_prob * (r+gamma*V[next_state]) # <-これがベルマン方程式\n",
    "        V[state] = new_V\n",
    "    return V\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "# 以上の関数を繰り返し行うことで(更新する数値がある値よりも少なくなった場合)状態価値関数が決定する\n",
    "def policy_eval(pi,V,env,gamma,check_value = 0.001):\n",
    "\n",
    "    while True:\n",
    "        # まずは以前使った状態価値関数を保持する(更新後と更新前で比較)\n",
    "        # また参照わたしにならないように値渡しを用いて(copy)保持\n",
    "        old_V = copy.copy(V)\n",
    "        V = eval_step(pi,V,env,gamma)\n",
    "\n",
    "        # 更新された量の最大値を求める\n",
    "        update_value = 0\n",
    "        for state in V.keys(): #state=(0,0),(0,1)...\n",
    "            t = abs(V[state] - old_V[state]) # 更新した値の絶対値を保持\n",
    "            update_value += t\n",
    "            # 更新された値がcheck_valueより小さかったらループを抜ける\n",
    "        if update_value < check_value:\n",
    "            end_time = time.time() - start\n",
    "            break\n",
    "\n",
    "    return V\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7fe64993a160>, {(0, 0): -0.4497237522905997, (1, 0): -0.8767635718254536, (0, 1): -0.22283230286911446, (0, 2): -0.09510793716072946, (1, 2): -1.215930409302978, (0, 3): 0, (2, 0): -1.693686220134511, (2, 1): -1.7388141490081546, (1, 1): -0.9122080423709611, (2, 2): -1.9608484439762819, (1, 3): -1.0212271560549966, (2, 3): -2.301682988284246, (3, 0): -2.107294236625818, (3, 1): -2.334853561042618, (3, 2): -2.3474162060864843, (3, 3): -2.723790082547313, (4, 0): -2.1189728605164686, (4, 1): -1.9614694364186716, (4, 2): -2.30243629074953, (4, 3): -2.510697464034327})\n",
      "0.00512385368347168\n"
     ]
    }
   ],
   "source": [
    "# 実際に状態価値関数を実装する\n",
    "env = GridWorld()\n",
    "gamma = 0.9 #割引率\n",
    "pi = defaultdict(lambda: {0:0.25,1:0.25,2:0.25,3:0.25})\n",
    "V = defaultdict(lambda :0)\n",
    "# 新しく時間計測を指定\n",
    "start = time.time()\n",
    "V = policy_eval(pi,V,env,gamma)\n",
    "process_time = time.time() - start\n",
    "print(V)\n",
    "print(process_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ここでグラフ化\n",
    "# 1. さっきまでの手順を関数化\n",
    "x = list()\n",
    "y = list()\n",
    "tile_list =np.array(\n",
    "            [[0,0,0,1],\n",
    "            [0,None,0,-1],\n",
    "            [0,0,0,0]]\n",
    "        )\n",
    "\n",
    "\n",
    "def count_time(tile_list,x,y,start):\n",
    "    env = GridWorld()\n",
    "    env.reward_map = tile_list\n",
    "    env.start = (4+start,0)\n",
    "    gamma = 0.9 #割引率\n",
    "    pi = defaultdict(lambda: {0:0.25,1:0.25,2:0.25,3:0.25})\n",
    "    V = defaultdict(lambda :0)\n",
    "    start = time.time()\n",
    "    V = policy_eval(pi,V,env,gamma)\n",
    "    process_time = time.time() - start\n",
    "    x.append(env.width*env.height)\n",
    "    y.append(process_time)\n",
    "\n",
    "for i in range(100):\n",
    "    count_time(tile_list,x,y,i)\n",
    "    tile_list = np.append(tile_list,[[0,0,-1,0]], axis=0)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44972375 -0.2228323  -0.09510794  0.        ]\n",
      " [-0.87676357 -0.91220804 -1.21593041 -1.02122716]\n",
      " [-1.69368622 -1.73881415 -1.96084844 -2.30168299]\n",
      " [-2.10729424 -2.33485356 -2.34741621 -2.72379008]\n",
      " [-2.11897286 -1.96146944 -2.30243629 -2.51069746]]\n"
     ]
    }
   ],
   "source": [
    "# ちょっとだけ綺麗に出力\n",
    "X = np.zeros((env.height, env.width))\n",
    "for i,j in V.items():\n",
    "    a,b = i\n",
    "    X[a][b] = j\n",
    "print(np.array(X))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 方策反復法\n",
    "- 以上で各々の状態価値関数を出力することができたので、続いて方策反復法を用いて最適方策を求めていく\n",
    "- 以前に導出した状態価値関数をもとに、方策を更新していき、その方策の更新で状態価値関数が更新されということを繰り返していく\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object GridWorld.states at 0x7fe649942970>"
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.states()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "# 方策を常に最大値に更新し続ける関数を作成する。\n",
    "def argmax(d):\n",
    "    max_value = max(d.values())\n",
    "    max_key = 0\n",
    "    for key,value in d.items():\n",
    "        if value == max_value:\n",
    "            max_key = key\n",
    "    # 行動の番号を返す(つまり前後左右どの方向に動くのがいいのかの番号を返す)\n",
    "    return max_key"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "# 方策反復法を用いて実装を行う\n",
    "# 引数に状態価値関数,方策,割引率を受け取る\n",
    "def greedy_policy(V,env,gamma):\n",
    "    pi = {}\n",
    "    for state in env.states():# (0, 0),(0, 1),(0, 2),(0, 3),(1, 0)...\n",
    "        action_values = {}\n",
    "        for action in env.actions:# [0, 1, 2, 3]\n",
    "            next_state = env.next_step(state,action)\n",
    "            r = env.reward(state,action,next_state)\n",
    "            value = r + gamma * V[next_state]\n",
    "            action_values[action] = value\n",
    "        max_action = argmax(action_values)\n",
    "        action_probs = {0:0,1:0,2:0,3:0}\n",
    "        action_probs[max_action] = 1.0\n",
    "        pi[state] = action_probs\n",
    "    return pi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "def policy_iter(env,gamma,check_value = 0.001):\n",
    "    pi = defaultdict(lambda :{0:0.25,1:0.25,2:0.25,3:0.25})\n",
    "    V = defaultdict(lambda :0)\n",
    "\n",
    "    while True:\n",
    "        V = policy_eval(pi,V,env,gamma,check_value)\n",
    "        new_pi = greedy_policy(V,env,gamma)\n",
    "\n",
    "        if new_pi == pi:\n",
    "            break\n",
    "        pi = new_pi\n",
    "    return pi\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "env = GridWorld()\n",
    "gamma = 0.9\n",
    "pi = policy_iter(env,gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "# 出力結果をわかりやすく出力\n",
    "# [0,1,2,3]が[\"上\",\"下\",\"左\",\"右\"]に対応,また障害物,ゴールは100で表す。\n",
    "def ans(pi,env):\n",
    "    X = np.zeros((env.height, env.width))\n",
    "    for i,j in pi.items():\n",
    "        a,b = i\n",
    "        if i == env.goal or i == env.wall:\n",
    "            X[a][b] = None\n",
    "        else:\n",
    "            move = argmax(j)\n",
    "            X[a][b] = move\n",
    "    return X\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 3.,  3.,  3., nan],\n       [ 0., nan,  0.,  0.],\n       [ 3.,  3.,  0.,  2.],\n       [ 3.,  0.,  0.,  0.],\n       [ 3.,  0.,  2.,  2.]])"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans(pi,env)\n",
    "#[[0,0,0,1],\n",
    "# [0,None,0,-1],\n",
    "# [0,0,0,0],\n",
    "# [-1,0,-1,-1],\n",
    "# [0,0,0,0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "# 動的計画法の限界を知りたい"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}